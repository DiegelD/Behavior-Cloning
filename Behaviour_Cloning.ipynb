{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self-Driving Car Engineer Nanodegree\n",
    "# Behaviour Cloning\n",
    "\n",
    "Project: Build a Traffic Sign Recognition Classifier\n",
    "In this notebook, a template is provided for you to implement your functionality in stages, which is required to successfully complete this project. If additional code is required that cannot be included in the notebook, be sure that the Python code is successfully imported and included in your submission if necessary.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 0: Load The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "Image_list = os.listdir(\"data/IMG/\")\n",
    "y_data_csv  = pd.read_csv('data/driving_log.csv')\n",
    "\n",
    "print(y_data_csv['center'][1])\n",
    "print(len(y_data_csv['center'][1]))\n",
    "path = y_data_csv['left'][1][1:]\n",
    "\n",
    "print(path)\n",
    "print(len(path))\n",
    "\n",
    "center_image = mpimg.imread('data/'+y_data_csv['center'][1])\n",
    "print('This image is:', type(center_image), 'with dimensions:', center_image.shape)\n",
    "\n",
    "\n",
    "crop_img = center_image[60:140,0:320] \n",
    "print('This image is:', type(crop_img), 'with dimensions:', crop_img.shape)\n",
    "\n",
    "left_image = mpimg.imread('data/'+y_data_csv['left'][1][1:])\n",
    "print('This image is:', type(center_image), 'with dimensions:', center_image.shape)\n",
    "\n",
    "\n",
    "left_crop_img = center_image[60:140,0:320] \n",
    "print('This image is:', type(crop_img), 'with dimensions:', crop_img.shape)\n",
    "\n",
    "fig, (ax1, ax2,ax3,ax4) = plt.subplots(1,4, figsize=(15, 35))\n",
    "ax1.imshow(center_image)\n",
    "ax1.set_title('Center Original')    \n",
    "ax1.axis('ON')  # clear x- and y-axes\n",
    "ax2.imshow(crop_img)\n",
    "ax2.set_title('Center CropedÂ°')    \n",
    "ax2.axis('ON')  # clear x- and y-axes \n",
    "ax3.imshow(left_image)\n",
    "ax3.set_title('Left Orginal')    \n",
    "ax3.axis('ON')  # clear x- and y-axes\n",
    "ax4.imshow(left_crop_img)\n",
    "ax4.set_title('Left Croped')    \n",
    "ax4.axis('ON')  # clear x- and y-axes \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = []\n",
    "y_data = []\n",
    "for row in range(len(y_data_csv)):\n",
    "    X_data.append(mpimg.imread('data/'+y_data_csv['center'][row]))  \n",
    "    X_data.append(mpimg.imread('data/'+y_data_csv['left'][row].strip()))   # strip() to delte space in the string\n",
    "    X_data.append(mpimg.imread('data/'+y_data_csv['right'][row].strip())) \n",
    " \n",
    "    for i in range(3):\n",
    "        y_data.append(y_data_csv['steering'][row])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crop the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crop image, due to less net parameter\n",
    "for i in range(len(X_data)):\n",
    "    X_data[i] = X_data[i][60:140,0:320]   # box=(y:y+crop, x:x+crop)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check if the data sets coherent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "#from sklearn.model_selection import train_test_split\n",
    "\n",
    "assert(len(X_data) == len(X_data))\n",
    "\n",
    "# Transform the data into np.arrays for the net\n",
    "X_data = np.array(X_data)\n",
    "y_data = np.array(y_data)\n",
    "\n",
    "# shuffle the data\n",
    "#X_data, y_data = shuffle(X_data, y_data)\n",
    "\n",
    "# Split the Data into Training and Validation Sets\n",
    "#X_train, X_valid, y_train, y_valid = train_test_split(X_data, y_data, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Dataset Summary & Exploration\n",
    "\n",
    "Provide a Basic Summary of the Data Set\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples = 24108\n",
      "Number of training labels = 24108\n",
      "Image data shape = 80 320 3\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Number of training examples\n",
    "n_train = len(X_data)\n",
    "\n",
    "# Number of training lables\n",
    "n_y_train = len(y_data)\n",
    "\n",
    "# Number of validation examples\n",
    "#n_validation = X_valid.shape[0]\n",
    "\n",
    "# Number of validation lables\n",
    "#n_y_validation = y_valid.shape[0]\n",
    "\n",
    "# What's the shape of an traffic sign image?\n",
    "image_shape = X_data[1].shape\n",
    "\n",
    "print(\"Number of training samples =\", n_train)\n",
    "print(\"Number of training labels =\", n_y_train)#\n",
    "#print(\"Number of validation samples =\", n_validat#ion)\n",
    "#print(\"Number of validation labels =\", n_y_validation)\n",
    "print(\"Image data shape =\", image_shape[0],image_shape[1],image_shape[2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## Step 2: Design and Test a Model Architecture\n",
    "\n",
    "Design and implement a deep learning model that learns to recognize traffic signs. Train and test your model on the [German Traffic Sign Dataset](http://benchmark.ini.rub.de/?section=gtsrb&subsection=dataset).\n",
    "\n",
    "There are various aspects to consider when thinking about this problem:\n",
    "\n",
    "- Neural network architecture (is the network over or underfitting?)\n",
    "- Play around preprocessing techniques (normalization, rgb to grayscale, etc)\n",
    "- Number of examples per label (some have more than others).\n",
    "- Generate fake data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization of the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# No need - Is done in the layers\n",
    "\n",
    "#for i in range(len(X_data)):\n",
    "#    X_data[i] = cv2.normalize(X_data[i],None,0,128,cv2.NORM_MINMAX) #normalizeFunction istheproble\n",
    "    \n",
    "#for i in range(len(X_valid)):\n",
    " #   X_valid[i] = cv2.normalize(X_valid[i],None,0,128,cv2.NORM_MINMAX) #normalizeFunction istheproble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Architecture\n",
    "\n",
    "---\n",
    "\n",
    "#### Setup Keras\n",
    "\n",
    "The `EPOCH` and `BATCH_SIZE` values affect the training speed and model accuracy.\n",
    "You do not need to modify this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/DanielD/opt/miniconda3/envs/Behaviour_Cloning/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/DanielD/opt/miniconda3/envs/Behaviour_Cloning/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/DanielD/opt/miniconda3/envs/Behaviour_Cloning/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/DanielD/opt/miniconda3/envs/Behaviour_Cloning/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/DanielD/opt/miniconda3/envs/Behaviour_Cloning/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/DanielD/opt/miniconda3/envs/Behaviour_Cloning/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Users/DanielD/opt/miniconda3/envs/Behaviour_Cloning/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/DanielD/opt/miniconda3/envs/Behaviour_Cloning/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/DanielD/opt/miniconda3/envs/Behaviour_Cloning/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/DanielD/opt/miniconda3/envs/Behaviour_Cloning/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/DanielD/opt/miniconda3/envs/Behaviour_Cloning/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/DanielD/opt/miniconda3/envs/Behaviour_Cloning/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "#EPOCHS = 3\n",
    "#BATCH_SIZE = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Keras\n",
    "\n",
    "os.environ[\"KERAS_BACKEND\"] = \"plaidml.keras.backend\"         # To use eGPU on MAC\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Flatten, Dropout\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.layers import Lambda\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implement CNN architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the Final Test Neural Network in Keras Here\n",
    "model = Sequential()\n",
    "model.add(Lambda(lambda x: (x / 255.0) - 0.5, input_shape=(80, 320, 3)))     # normalization\n",
    "\n",
    "model.add(Conv2D(3,  (5, 5), strides=(2, 2), activation='relu'))\n",
    "model.add(Conv2D(24, (5, 5), strides=(2, 2), activation='relu'))\n",
    "model.add(Conv2D(36, (5, 5), strides=(2, 2), activation='relu'))\n",
    "model.add(Conv2D(48, (3, 3),                 activation='relu'))\n",
    "model.add(Conv2D(64, (3, 3),                 activation='relu'))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(50,  activation='relu'))\n",
    "model.add(Dense(10,  activation='relu'))\n",
    "model.add(Dense(1,                    ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 19286 samples, validate on 4822 samples\n",
      "Epoch 1/10\n",
      "19286/19286 [==============================] - 66s 3ms/step - loss: 0.0108 - accuracy: 0.0000e+00 - val_loss: 0.0106 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "19286/19286 [==============================] - 64s 3ms/step - loss: 0.0094 - accuracy: 0.0000e+00 - val_loss: 0.0107 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "19286/19286 [==============================] - 65s 3ms/step - loss: 0.0091 - accuracy: 0.0000e+00 - val_loss: 0.0109 - val_accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "# compile and fit model\n",
    "callbacks = EarlyStopping( monitor='val_loss',min_delta=0, mode='auto', restore_best_weights=True, patience=2)\n",
    "\n",
    "model.compile( optimizer='adam', loss=\"mse\", metrics=[tf.keras.metrics.Accuracy()])\n",
    "history = model.fit(X_data,y_data, validation_split=0.2, shuffle=True, callbacks = [callbacks], epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the model\n",
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
